# IMG to VIDEO Workflow - WebUI Wrapper v3.0 (Token-based)
# Uses token replacement for robust workflow updates
# Tokens are embedded in the canvas JSON file and replaced at generation time

name: "IMG to VIDEO (Canvas)"
description: "Generate video from a single image using WAN 2.2 Image-to-Video model with high/low noise dual sampling"
version: "3.0.0"
category: "video"
tags:
  - image-to-video
  - wan-2.2
  - video-generation
  - 14B-model

# Workflow JSON file reference (canvas format)
workflow_file: "IMG_to_VIDEO_canvas.json"

# Thumbnail/preview image (optional)
thumbnail: null

# Estimated VRAM requirement
vram_estimate: "24GB"

# Estimated generation time (in seconds, approximate)
time_estimate:
  min: 120
  max: 600
  note: "Varies significantly based on duration and resolution"

# UI Layout Configuration - Section-based layout for organized UI
layout:
  sections:
    - id: "basic"
      title: "üìù Basic Settings"
      collapsed: false
      
    - id: "generation"
      title: "‚öôÔ∏è Generation Parameters"
      collapsed: false
      
    - id: "models"
      title: "üéØ Model Selection"
      collapsed: false
      
    - id: "features"
      title: "üîß Advanced Features"
      collapsed: true

# Helper Tools (not workflow fields, but UI utilities)
helper_tools:
  - id: "auto_sizing"
    type: "auto_size_calculator"
    label: "Automatic Sizing"
    description: "Calculate optimal output dimensions based on input image aspect ratio"
    position: "header"  # Display below workflow title/description
    controls:
      - id: "max_image_size"
        type: "slider_with_apply"
        label: "Max Image Size"
        description: "Limits image size by scaling down if it exceeds the specified megapixels."
        min: 0.1
        max: 4.0
        step: 0.1
        default: 1.0
        unit: "MP"
        apply_button: true
        apply_button_label: "Apply"
        apply_button_enabled_when: "value_changed"
      - id: "auto_size_toggle"
        type: "checkbox"
        label: "Enable Automatic Sizing"
        description: "When enabled, Width and Height will be automatically calculated and those fields will be disabled"
        default: false
        position: "inline_right"  # Display inline to the right of max_image_size slider
    targets:
      width_field: "size_x"
      height_field: "size_y"
    requires:
      - "input_image"
    triggers:
      - "input_image_upload"
      - "auto_size_toggle_change"
      - "max_image_size_apply"
    behavior:
      when_enabled:
        - disable_field: "size_x"
        - disable_field: "size_y"
        - calculate_and_update: ["size_x", "size_y"]
      when_disabled:
        - enable_field: "size_x"
        - enable_field: "size_y"
      calculation_method: "maintain_aspect_ratio_fit_max"
      snap_to_grid: 64

# Token-based inputs - no node IDs required!
inputs:
  # === BASIC SETTINGS ===
  - id: "input_image"
    section: "basic"
    token: "{{INPUT_IMAGE}}"
    type: "image"
    label: "Input Image"
    description: "Source image to animate. Will be resized to fit the selected output size."
    required: true
    accept: "image/png,image/jpeg,image/webp"
    max_size_mb: 10

  - id: "positive_prompt"
    section: "basic"
    token: "{{POSITIVE_PROMPT}}"
    type: "textarea"
    label: "Positive Prompt"
    description: "Describe the motion and style you want in the video"
    required: true
    default: "The subject moves naturally with smooth cinematic motion, high quality, detailed"
    placeholder: "Describe the desired motion and style..."
    max_length: 2000
    rows: 4

  - id: "negative_prompt"
    section: "basic"
    token: "{{NEGATIVE_PROMPT}}"
    type: "textarea"
    label: "Negative Prompt"
    description: "What to avoid in the generation"
    required: false
    default: "Ëâ≤Ë∞ÉËâ≥‰∏ΩÔºåËøáÊõùÔºåÈùôÊÄÅÔºåÁªÜËäÇÊ®°Á≥ä‰∏çÊ∏ÖÔºåÂ≠óÂπïÔºåÈ£éÊ†ºÔºå‰ΩúÂìÅÔºåÁîª‰ΩúÔºåÁîªÈù¢ÔºåÈùôÊ≠¢ÔºåÊï¥‰ΩìÂèëÁÅ∞ÔºåÊúÄÂ∑ÆË¥®ÈáèÔºå‰ΩéË¥®ÈáèÔºåJPEGÂéãÁº©ÊÆãÁïôÔºå‰∏ëÈôãÁöÑÔºåÊÆãÁº∫ÁöÑÔºåÂ§ö‰ΩôÁöÑÊâãÊåáÔºåÁîªÂæó‰∏çÂ•ΩÁöÑÊâãÈÉ®ÔºåÁîªÂæó‰∏çÂ•ΩÁöÑËÑ∏ÈÉ®ÔºåÁï∏ÂΩ¢ÁöÑÔºåÊØÅÂÆπÁöÑÔºåÂΩ¢ÊÄÅÁï∏ÂΩ¢ÁöÑËÇ¢‰ΩìÔºåÊâãÊåáËûçÂêàÔºåÈùôÊ≠¢‰∏çÂä®ÁöÑÁîªÈù¢ÔºåÊùÇ‰π±ÁöÑËÉåÊôØÔºå‰∏âÊù°ËÖøÔºåËÉåÊôØ‰∫∫ÂæàÂ§öÔºåÂÄíÁùÄËµ∞, fast movements, blurry, mouth moving, talking, teeth visible, strong blush"
    rows: 3

  - id: "seed"
    section: "basic"
    token: "{{SEED}}"
    type: "seed"
    label: "Seed"
    description: "Random seed for reproducibility (-1 for random)"
    randomize_button: true
    default: -1
    control_after_generate: "randomize"

  # === GENERATION PARAMETERS ===
  - id: "size_x"
    section: "generation"
    token: "{{SIZE_WIDTH}}"
    type: "slider"
    label: "Width"
    description: "Output width in pixels"
    min: 512
    max: 1920
    step: 64
    default: 896
    unit: "px"
    controlled_by: "auto_size_enabled"
    auto_calculate: true

  - id: "size_y"
    section: "generation"
    token: "{{SIZE_HEIGHT}}"
    type: "slider"
    label: "Height"
    description: "Output height in pixels"
    min: 512
    max: 1920
    step: 64
    default: 1120
    unit: "px"

  - id: "duration"
    section: "generation"
    token: "{{DURATION}}"
    type: "slider"
    label: "Duration"
    description: "Video length in seconds"
    min: 1.0
    max: 10.0
    step: 0.5
    default: 5.0
    unit: "seconds"

  - id: "steps"
    section: "generation"
    token: "{{STEPS}}"
    type: "slider"
    label: "Steps"
    description: "Denoising steps. Higher = better quality but slower."
    min: 10
    max: 40
    step: 1
    default: 20

  - id: "cfg"
    section: "generation"
    token: "{{CFG}}"
    type: "slider"
    label: "CFG Scale"
    description: "Prompt adherence strength. Higher = more prompt influence."
    min: 1.0
    max: 10.0
    step: 0.5
    default: 3.5

  - id: "frame_rate"
    section: "generation"
    token: "{{FRAME_RATE}}"
    type: "slider"
    label: "Frame Rate"
    description: "Output frames per second"
    min: 8.0
    max: 24.0
    step: 1.0
    default: 16.0
    unit: "FPS"

  - id: "speed"
    section: "generation"
    token: "{{SPEED}}"
    type: "slider"
    label: "Sampling Speed"
    description: "ModelSamplingSD3 shift parameter"
    min: 1.0
    max: 15.0
    step: 0.5
    default: 7.0

  - id: "upscale_ratio"
    section: "generation"
    token: "{{UPSCALE_RATIO}}"
    type: "slider"
    label: "Upscale Ratio"
    description: "Scale factor for upscaling"
    min: 1.0
    max: 4.0
    step: 0.5
    default: 2.0

  # === MODEL SELECTION ===
  - id: "main_model"
    section: "models"
    type: "high_low_pair_model"
    label: "Main Model (High/Low Noise Pair)"
    description: "Diffusion model pair for generation. Click refresh to scan instance for available models."
    required: true
    model_type: "diffusion_models"
    tokens:
      high: "{{WAN_HIGH_MODEL}}"
      low: "{{WAN_LOW_MODEL}}"
    default_high: "Wan-2.2_ComfyUI_repackaged/wan2.2_i2v_high_noise_14B_fp16.safetensors"
    default_low: "Wan-2.2_ComfyUI_repackaged/wan2.2_i2v_low_noise_14B_fp16.safetensors"

  - id: "loras"
    section: "models"
    node_ids:
      - "416"  # high noise LoRA loader
      - "471"  # low noise LoRA loader
    type: "high_low_pair_lora_list"
    label: "LoRAs (High/Low Noise Pairs)"
    description: "Add LoRAs for style/motion control. Each LoRA should have high/low noise variants."
    required: false
    model_type: "loras"
    max_items: 5

  - id: "clip_model"
    section: "models"
    token: "{{CLIP_MODEL}}"
    type: "single_model"
    label: "CLIP Model"
    description: "Text encoder model"
    required: true
    model_type: "text_encoders"
    default: "Wan-2.2/umt5_xxl_fp16.safetensors"

  - id: "vae_model"
    section: "models"
    token: "{{VAE_MODEL}}"
    type: "single_model"
    label: "VAE Model"
    description: "Variational autoencoder"
    required: true
    model_type: "vae"
    default: "Wan-2.1/wan_2.1_vae.safetensors"

  - id: "upscale_model"
    section: "models"
    token: "{{UPSCALE_MODEL}}"
    type: "single_model"
    label: "Upscale Model"
    description: "Super-resolution model for upscaling"
    required: false
    model_type: "upscale_models"
    default: "RealESRGAN_x4plus.pth"

  # === ADVANCED FEATURES ===
  
  # Output & Enhancement Toggles
  - id: "save_last_frame"
    section: "features"
    node_ids:
      - "447"  # SaveImage node
      - "444"  # ImageFromBatch node
    type: "node_mode_toggle"
    label: "Save Last Frame"
    description: "Save the final frame as a separate image output"
    required: false
    default: 2  # mode: 2 = disabled (bypass)

  - id: "enable_interpolation"
    section: "features"
    node_ids:
      - "431"  # RIFE VFI node (base interpolation)
      - "433"  # VHS_VideoCombine (Save Interpoled)
    type: "node_mode_toggle"
    label: "Enable Interpolation (RIFE)"
    description: "Use RIFE to interpolate frames and increase smoothness"
    required: false
    default: 0  # mode: 0 = enabled

  - id: "use_upscaler"
    section: "features"
    node_ids:
      - "385"  # ImageUpscaleWithModel node
      - "418"  # ImageScaleBy (Apply ratio) node
    type: "node_mode_toggle"
    label: "Enable Upscaler"
    description: "Apply AI upscaling to the input image before video generation. Uses the upscale model and ratio configured above."
    required: false
    default: 2  # mode: 2 = disabled (bypass)

  - id: "enable_upscale_interpolation"
    section: "features"
    node_ids:
      - "442"  # RIFE VFI node (upscale path)
      - "443"  # VHS_VideoCombine (Save UPINT)
    type: "node_mode_toggle"
    label: "Enable Upscale + Interpolation"
    description: "Apply both upscaling and frame interpolation (combines both techniques)"
    required: false
    default: 2  # mode: 2 = disabled (bypass)

  - id: "enable_video_enhancer"
    section: "features"
    node_ids:
      - "481"  # WanVideoEnhanceAVideoKJ (Enhance High)
      - "482"  # WanVideoEnhanceAVideoKJ (Enhance Low)
    type: "node_mode_toggle"
    label: "Video Enhancer (WanVideoEnhanceAVideoKJ)"
    description: "Apply WAN video enhancement for improved quality"
    required: false
    default: 0  # mode: 0 = enabled

  - id: "enable_cfg_zero_star"
    section: "features"
    node_ids:
      - "483"  # CFGZeroStarAndInit (CFG Zero High)
      - "484"  # CFGZeroStarAndInit (CFG Zero Low)
    type: "node_mode_toggle"
    label: "CFGZeroStar"
    description: "Enable CFG guidance enhancement for better prompt adherence"
    required: false
    default: 0  # mode: 0 = enabled

  - id: "enable_speed_regulation"
    section: "features"
    node_ids:
      - "467"  # ModelSamplingSD3 (SamplingHigh)
      - "468"  # ModelSamplingSD3 (SamplingLow)
    type: "node_mode_toggle"
    label: "Speed Regulation"
    description: "Enable ModelSamplingSD3 speed control for sampling adjustments"
    required: false
    default: 0  # mode: 0 = enabled

  - id: "enable_normalized_attention"
    section: "features"
    node_ids:
      - "485"  # WanVideoNAG (NAG High)
      - "486"  # WanVideoNAG (NAG Low)
    type: "node_mode_toggle"
    label: "Normalized Attention (WanVideoNAG)"
    description: "Apply normalized attention guidance for better consistency"
    required: false
    default: 0  # mode: 0 = enabled

  # Performance & Memory
  - id: "enable_magcache"
    section: "features"
    node_ids:
      - "506"  # MagCache Low
    type: "node_mode_toggle"
    label: "MagCache"
    description: "Enable memory caching to speed up repeated operations"
    required: false
    default: 0  # mode: 0 = enabled

  - id: "enable_torch_compile"
    section: "features"
    node_ids:
      - "492"  # TorchCompileModelWanVideo (Compile High)
      - "494"  # TorchCompileModelWanVideo (Compile Low)
    type: "node_mode_toggle"
    label: "TorchCompile"
    description: "Enable JIT compilation for faster execution (first run will be slower)"
    required: false
    default: 4  # mode: 4 = muted (disabled)

  - id: "enable_block_swap"
    section: "features"
    node_ids:
      - "500"  # wanBlockSwap (BlockSwap High)
      - "501"  # wanBlockSwap (BlockSwap Low)
    type: "node_mode_toggle"
    label: "BlockSwap"
    description: "Enable model offloading to reduce VRAM usage at the cost of speed"
    required: false
    default: 0  # mode: 0 = enabled

  # VRAM Control
  - id: "vram_reduction"
    section: "features"
    node_ids:
      - "502"  # mxSlider (Reduce VRAM usage - BlockSwap)
    token: "{{VRAM_REDUCTION}}"
    type: "slider"
    label: "VRAM Reduction"
    description: "Percentage of model to offload to system RAM (0% = all in VRAM, 100% = maximum offloading)"
    min: 0
    max: 100
    step: 1
    default: 100
    unit: "%"

# Output configuration
outputs:
  - id: "original_video"
    node_id: "398"  # Still need node_id to identify output nodes
    type: "video"
    format: "mp4"
    label: "Original Video"
    description: "Video at native frame rate with color matching"

# Model requirements (for validation and display)
requirements:
  models:
    - type: "unet"
      name: "WAN 2.2 High Noise 14B"
      path: "Wan-2.2_ComfyUI_repackaged/wan2.2_i2v_high_noise_14B_fp16.safetensors"
      size_gb: 27.8
    - type: "unet"
      name: "WAN 2.2 Low Noise 14B"
      path: "Wan-2.2_ComfyUI_repackaged/wan2.2_i2v_low_noise_14B_fp16.safetensors"
      size_gb: 27.8
    - type: "clip"
      name: "UMT5 XXL"
      path: "Wan-2.2/umt5_xxl_fp16.safetensors"
      size_gb: 9.8
    - type: "vae"
      name: "WAN 2.1 VAE"
      path: "Wan-2.1/wan_2.1_vae.safetensors"
      size_gb: 0.2
    - type: "upscale"
      name: "RealESRGAN x4 Plus"
      path: "RealESRGAN_x4plus.pth"
      size_gb: 0.06

  custom_nodes:
    - name: "ComfyUI-VideoHelperSuite"
      repo: "https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite"
      required: true
    - name: "ComfyUI-KJNodes"
      repo: "https://github.com/kijai/ComfyUI-KJNodes"
      required: true
    - name: "rgthree-comfy"
      repo: "https://github.com/rgthree/rgthree-comfy"
      required: true
    - name: "ComfyUI-mxToolkit"
      repo: "https://github.com/Intersection98/ComfyUI_mxToolkit"
      required: true
    - name: "ComfyUI-WanVideoWrapper"
      repo: "https://github.com/kijai/ComfyUI-WanVideoWrapper"
      required: true
    - name: "ComfyUI-Easy-Use"
      repo: "https://github.com/yolain/ComfyUI-Easy-Use"
      required: true

  vram: "24GB minimum (48GB recommended for longer videos)"
  compute: "NVIDIA GPU with CUDA support"

# Presets for quick configuration
presets:
  - name: "Quick Preview"
    description: "Fast generation for testing"
    values:
      duration: 2.0
      steps: 15
      frame_rate: 12.0
      upscale_ratio: 1.0

  - name: "High Quality"
    description: "Best quality, slower generation"
    values:
      duration: 5.0
      steps: 30
      frame_rate: 24.0
      upscale_ratio: 2.0

  - name: "Balanced"
    description: "Good balance of quality and speed"
    values:
      duration: 5.0
      steps: 20
      frame_rate: 16.0
      upscale_ratio: 1.5
