# IMG to VIDEO Workflow - WebUI Wrapper v3.0 (Token-based)
# Uses token replacement for robust workflow updates
# Tokens are embedded in the canvas JSON file and replaced at generation time

name: "IMG to VIDEO (Canvas)"
description: "Generate video from a single image using WAN 2.2 Image-to-Video model with high/low noise dual sampling"
version: "3.0.0"
category: "video"
tags:
  - image-to-video
  - wan-2.2
  - video-generation
  - 14B-model

# Workflow JSON file reference (canvas format)
workflow_file: "IMG_to_VIDEO_canvas.json"

# Thumbnail/preview image (optional)
thumbnail: null

# Estimated VRAM requirement
vram_estimate: "24GB"

# Estimated generation time (in seconds, approximate)
time_estimate:
  min: 120
  max: 600
  note: "Varies significantly based on duration and resolution"

# UI Layout Configuration - Section-based layout for organized UI
layout:
  sections:
    - id: "basic"
      title: "ğŸ“ Basic Settings"
      collapsed: false
      
    - id: "generation"
      title: "âš™ï¸ Generation Parameters"
      collapsed: false
      
    - id: "models"
      title: "ğŸ¯ Model Selection"
      collapsed: false
      
    - id: "features"
      title: "ğŸ”§ Advanced Features"
      collapsed: true

# Token-based inputs - no node IDs required!
inputs:
  # === BASIC SETTINGS ===
  - id: "input_image"
    section: "basic"
    token: "{{INPUT_IMAGE}}"
    type: "image"
    label: "Input Image"
    description: "Source image to animate. Will be resized to fit the selected output size."
    required: true
    accept: "image/png,image/jpeg,image/webp"
    max_size_mb: 10

  - id: "positive_prompt"
    section: "basic"
    token: "{{POSITIVE_PROMPT}}"
    type: "textarea"
    label: "Positive Prompt"
    description: "Describe the motion and style you want in the video"
    required: true
    default: "The subject moves naturally with smooth cinematic motion, high quality, detailed"
    placeholder: "Describe the desired motion and style..."
    max_length: 2000
    rows: 4

  - id: "negative_prompt"
    section: "basic"
    token: "{{NEGATIVE_PROMPT}}"
    type: "textarea"
    label: "Negative Prompt"
    description: "What to avoid in the generation"
    required: false
    default: "è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°, fast movements, blurry, mouth moving, talking, teeth visible, strong blush"
    rows: 3

  - id: "seed"
    section: "basic"
    token: "{{SEED}}"
    type: "seed"
    label: "Seed"
    description: "Random seed for reproducibility (-1 for random)"
    randomize_button: true
    default: -1
    control_after_generate: "randomize"

  # === GENERATION PARAMETERS ===
  - id: "size_x"
    section: "generation"
    token: "{{SIZE_WIDTH}}"
    type: "slider"
    label: "Width"
    description: "Output width in pixels"
    min: 512
    max: 1920
    step: 64
    default: 896
    unit: "px"

  - id: "size_y"
    section: "generation"
    token: "{{SIZE_HEIGHT}}"
    type: "slider"
    label: "Height"
    description: "Output height in pixels"
    min: 512
    max: 1920
    step: 64
    default: 1120
    unit: "px"

  - id: "duration"
    section: "generation"
    token: "{{DURATION}}"
    type: "slider"
    label: "Duration"
    description: "Video length in seconds"
    min: 1.0
    max: 10.0
    step: 0.5
    default: 5.0
    unit: "seconds"

  - id: "steps"
    section: "generation"
    token: "{{STEPS}}"
    type: "slider"
    label: "Steps"
    description: "Denoising steps. Higher = better quality but slower."
    min: 10
    max: 40
    step: 1
    default: 20

  - id: "cfg"
    section: "generation"
    token: "{{CFG}}"
    type: "slider"
    label: "CFG Scale"
    description: "Prompt adherence strength. Higher = more prompt influence."
    min: 1.0
    max: 10.0
    step: 0.5
    default: 3.5

  - id: "frame_rate"
    section: "generation"
    token: "{{FRAME_RATE}}"
    type: "slider"
    label: "Frame Rate"
    description: "Output frames per second"
    min: 8.0
    max: 24.0
    step: 1.0
    default: 16.0
    unit: "FPS"

  - id: "speed"
    section: "generation"
    token: "{{SPEED}}"
    type: "slider"
    label: "Sampling Speed"
    description: "ModelSamplingSD3 shift parameter"
    min: 1.0
    max: 15.0
    step: 0.5
    default: 7.0

  - id: "upscale_ratio"
    section: "generation"
    token: "{{UPSCALE_RATIO}}"
    type: "slider"
    label: "Upscale Ratio"
    description: "Scale factor for upscaling"
    min: 1.0
    max: 4.0
    step: 0.5
    default: 2.0

  # === MODEL SELECTION ===
  - id: "main_model"
    section: "models"
    type: "high_low_pair_model"
    label: "Main Model (High/Low Noise Pair)"
    description: "Diffusion model pair for generation. Click refresh to scan instance for available models."
    required: true
    model_type: "diffusion_models"
    tokens:
      high: "{{WAN_HIGH_MODEL}}"
      low: "{{WAN_LOW_MODEL}}"
    default_high: "Wan-2.2_ComfyUI_repackaged/wan2.2_i2v_high_noise_14B_fp16.safetensors"
    default_low: "Wan-2.2_ComfyUI_repackaged/wan2.2_i2v_low_noise_14B_fp16.safetensors"

  - id: "loras"
    section: "models"
    node_ids:
      - "416"  # high noise LoRA loader
      - "471"  # low noise LoRA loader
    type: "high_low_pair_lora_list"
    label: "LoRAs (High/Low Noise Pairs)"
    description: "Add LoRAs for style/motion control. Each LoRA should have high/low noise variants."
    required: false
    model_type: "loras"
    max_items: 5

  - id: "clip_model"
    section: "models"
    token: "{{CLIP_MODEL}}"
    type: "single_model"
    label: "CLIP Model"
    description: "Text encoder model"
    required: true
    model_type: "text_encoders"
    default: "Wan-2.2/umt5_xxl_fp16.safetensors"

  - id: "vae_model"
    section: "models"
    token: "{{VAE_MODEL}}"
    type: "single_model"
    label: "VAE Model"
    description: "Variational autoencoder"
    required: true
    model_type: "vae"
    default: "Wan-2.1/wan_2.1_vae.safetensors"

  - id: "upscale_model"
    section: "models"
    token: "{{UPSCALE_MODEL}}"
    type: "single_model"
    label: "Upscale Model"
    description: "Super-resolution model for upscaling"
    required: false
    model_type: "upscale_models"
    default: "RealESRGAN_x4plus.pth"

  # === ADVANCED FEATURES ===
  # Note: Feature toggles would require mode tokens in canvas JSON
  # For now, these features are controlled by the workflow's node mode settings

# Output configuration
outputs:
  - id: "original_video"
    node_id: "398"  # Still need node_id to identify output nodes
    type: "video"
    format: "mp4"
    label: "Original Video"
    description: "Video at native frame rate with color matching"

# Model requirements (for validation and display)
requirements:
  models:
    - type: "unet"
      name: "WAN 2.2 High Noise 14B"
      path: "Wan-2.2_ComfyUI_repackaged/wan2.2_i2v_high_noise_14B_fp16.safetensors"
      size_gb: 27.8
    - type: "unet"
      name: "WAN 2.2 Low Noise 14B"
      path: "Wan-2.2_ComfyUI_repackaged/wan2.2_i2v_low_noise_14B_fp16.safetensors"
      size_gb: 27.8
    - type: "clip"
      name: "UMT5 XXL"
      path: "Wan-2.2/umt5_xxl_fp16.safetensors"
      size_gb: 9.8
    - type: "vae"
      name: "WAN 2.1 VAE"
      path: "Wan-2.1/wan_2.1_vae.safetensors"
      size_gb: 0.2
    - type: "upscale"
      name: "RealESRGAN x4 Plus"
      path: "RealESRGAN_x4plus.pth"
      size_gb: 0.06

  custom_nodes:
    - name: "ComfyUI-VideoHelperSuite"
      repo: "https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite"
      required: true
    - name: "ComfyUI-KJNodes"
      repo: "https://github.com/kijai/ComfyUI-KJNodes"
      required: true
    - name: "rgthree-comfy"
      repo: "https://github.com/rgthree/rgthree-comfy"
      required: true
    - name: "ComfyUI-mxToolkit"
      repo: "https://github.com/Intersection98/ComfyUI_mxToolkit"
      required: true
    - name: "ComfyUI-WanVideoWrapper"
      repo: "https://github.com/kijai/ComfyUI-WanVideoWrapper"
      required: true
    - name: "ComfyUI-Easy-Use"
      repo: "https://github.com/yolain/ComfyUI-Easy-Use"
      required: true

  vram: "24GB minimum (48GB recommended for longer videos)"
  compute: "NVIDIA GPU with CUDA support"

# Presets for quick configuration
presets:
  - name: "Quick Preview"
    description: "Fast generation for testing"
    values:
      duration: 2.0
      steps: 15
      frame_rate: 12.0
      upscale_ratio: 1.0

  - name: "High Quality"
    description: "Best quality, slower generation"
    values:
      duration: 5.0
      steps: 30
      frame_rate: 24.0
      upscale_ratio: 2.0

  - name: "Balanced"
    description: "Good balance of quality and speed"
    values:
      duration: 5.0
      steps: 20
      frame_rate: 16.0
      upscale_ratio: 1.5
